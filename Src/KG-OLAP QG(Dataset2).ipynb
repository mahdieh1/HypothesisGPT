{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwR3+YJVaRqLgx0owR9P2o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Generate graphs"],"metadata":{"id":"FA_2MaLlE5uv"}},{"cell_type":"markdown","source":["Graph 1:"],"metadata":{"id":"OnD9UFThFDWa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fXe4Y-qCrQu"},"outputs":[],"source":["import networkx as nx\n","import pandas as pd\n","import pickle\n","import os\n","\n","# Upload the Excel file to Google Colab and get the file path\n","uploaded_file_path = '/content/Network.xlsx'\n","excel_file = os.path.abspath(uploaded_file_path)\n","sheet_name = 'Gene-Diseasenetwork'\n","\n","# Read the Excel file and the first sheet\n","df = pd.read_excel(excel_file, sheet_name=sheet_name)\n","\n","# Create an empty graph\n","G_gene_disease = nx.Graph()\n","\n","# Get unique genes from column 1\n","genes = df.iloc[:, 0].unique()\n","\n","# Get unique diseases from column 3\n","diseases = df.iloc[:, 2].unique()\n","\n","# Iterate over the rows of the dataframe\n","for index, row in df.iterrows():\n","    node_a = row.iloc[0]  # Get value from the first column\n","    node_c = row.iloc[2]  # Get value from the third column\n","\n","    # Add nodes and edges to the graph\n","    G_gene_disease.add_node(node_a)\n","    G_gene_disease.add_node(node_c)\n","    G_gene_disease.add_edge(node_a, node_c)\n","\n","# Save the graph as a database file\n","output_path = '/content/gene_disease_network.pkl'\n","with open(output_path, 'wb') as f:\n","    pickle.dump(G_gene_disease, f)\n"]},{"cell_type":"markdown","source":["Graph 2:"],"metadata":{"id":"EuTjD9xcFAqX"}},{"cell_type":"code","source":["import networkx as nx\n","import pandas as pd\n","import pickle\n","import matplotlib.pyplot as plt\n","\n","# Define the file path and sheet name\n","excel_file = '/content/Network.xlsx'\n","sheet_name = 'Shared gene-disease network'\n","\n","# Read the Excel file and the specified sheet\n","df = pd.read_excel(excel_file, sheet_name=sheet_name)\n","\n","# Create an empty graph\n","G_shared_network = nx.Graph()\n","\n","# Iterate over the rows of the dataframe\n","for index, row in df.iterrows():\n","    node_a = row.iloc[0]  # Get value from the first column\n","    node_b = row.iloc[1]  # Get value from the second column\n","    weight = row.iloc[2]  # Get value from the third column\n","\n","    # Add nodes and edges to the graph\n","    G_shared_network.add_node(node_a)\n","    G_shared_network.add_node(node_b)\n","    G_shared_network.add_edge(node_a, node_b, weight=weight)\n","\n","# Create a figure and axis\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Position the nodes using a spring layout\n","pos = nx.spring_layout(G_shared_network, seed=42, k=0.3)\n","\n","# Draw the nodes and edges\n","edge_weights = [G_shared_network[u][v]['weight'] for u, v in G_shared_network.edges()]\n","node_colors = ['lightblue' for node in G_shared_network.nodes()]\n","nx.draw_networkx_nodes(G_shared_network, pos, ax=ax, node_size=200, node_color=node_colors)\n","nx.draw_networkx_edges(G_shared_network, pos, ax=ax, edge_color='gray', alpha=0.7)\n","nx.draw_networkx_labels(G_shared_network, pos, font_size=6)\n","\n","# Adjust the plot limits for better visibility\n","ax.margins(0.2)\n","\n","# Remove the axis labels\n","ax.set_xticks([])\n","ax.set_yticks([])\n","\n","# Remove the surrounding box\n","ax.spines['top'].set_visible(False)\n","ax.spines['bottom'].set_visible(False)\n","ax.spines['left'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","\n","# Save the graph as a pickle file\n","output_path = '/content/shared_gene_disease_network.pkl'\n","with open(output_path, 'wb') as f:\n","    pickle.dump(G_shared_network, f)\n"],"metadata":{"id":"4sX9M_d1E-fv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Graph 3:"],"metadata":{"id":"szUpS8brJOIN"}},{"cell_type":"code","source":["import networkx as nx\n","import pandas as pd\n","import pickle\n","import matplotlib.pyplot as plt\n","\n","# Define the file path and sheet name\n","excel_file = '/content/Network.xlsx'\n","sheet_name = 'PPI network String'\n","\n","# Read the Excel file and the specified sheet\n","df = pd.read_excel(excel_file, sheet_name=sheet_name)\n","\n","# Create an empty graph\n","G_ppi_network = nx.Graph()\n","\n","# Iterate over the rows of the dataframe\n","for index, row in df.iterrows():\n","    node_a = row.iloc[0]  # Get value from the first column\n","    node_b = row.iloc[2]  # Get value from the third column\n","\n","    # Add nodes and edges to the graph\n","    G_ppi_network.add_node(node_a)\n","    G_ppi_network.add_node(node_b)\n","    G_ppi_network.add_edge(node_a, node_b)\n","\n","# Create a figure and axis\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Position the nodes using a spring layout with increased k value\n","pos = nx.spring_layout(G_ppi_network, seed=42, k=0.3)\n","\n","# Draw the nodes and edges\n","node_colors = 'lightblue'\n","nx.draw_networkx_nodes(G_ppi_network, pos, ax=ax, node_size=200, node_color=node_colors)\n","nx.draw_networkx_edges(G_ppi_network, pos, ax=ax, edge_color='gray', alpha=0.7)\n","nx.draw_networkx_labels(G_ppi_network, pos, font_size=8)\n","\n","# Adjust the plot limits for better visibility\n","ax.margins(0.15)\n","\n","# Remove the axis labels\n","ax.set_xticks([])\n","ax.set_yticks([])\n","\n","# Remove the surrounding box\n","ax.spines['top'].set_visible(False)\n","ax.spines['bottom'].set_visible(False)\n","ax.spines['left'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","\n","# Save the graph as a pickle file\n","output_path = '/content/ppi_network_string.pkl'\n","with open(output_path, 'wb') as f:\n","    pickle.dump(G_ppi_network, f)\n"],"metadata":{"id":"kaF10VsoJKdP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Graph 4:"],"metadata":{"id":"qsLWr9bJJS1N"}},{"cell_type":"code","source":["import networkx as nx\n","import pandas as pd\n","import pickle\n","import matplotlib.pyplot as plt\n","\n","# Define the file path and sheet name\n","excel_file = '/content/Network.xlsx'\n","sheet_name = 'Expanded PGx biomarker interact'\n","\n","# Read the Excel file and the specified sheet\n","df = pd.read_excel(excel_file, sheet_name=sheet_name)\n","\n","# Create an empty graph\n","G_expanded_pgx = nx.Graph()\n","\n","# Iterate over the rows of the dataframe\n","for index, row in df.iterrows():\n","    node_a = row.iloc[0]  # Get value from the first column\n","    node_b = row.iloc[2]  # Get value from the third column\n","\n","    # Add nodes and edges to the graph\n","    G_expanded_pgx.add_node(node_a)\n","    G_expanded_pgx.add_node(node_b)\n","    G_expanded_pgx.add_edge(node_a, node_b)\n","\n","# Create a figure and axis\n","fig, ax = plt.subplots(figsize=(12, 8))\n","\n","# Position the nodes using a spring layout\n","pos = nx.spring_layout(G_expanded_pgx, seed=42)\n","\n","# Draw the nodes and edges\n","node_colors = 'lightblue'\n","nx.draw_networkx_nodes(G_expanded_pgx, pos, ax=ax, node_size=200, node_color=node_colors)\n","nx.draw_networkx_edges(G_expanded_pgx, pos, ax=ax, edge_color='gray', alpha=0.7)\n","nx.draw_networkx_labels(G_expanded_pgx, pos, font_size=8)\n","\n","# Adjust the plot limits for better visibility\n","ax.margins(0.15)\n","\n","# Remove the axis labels\n","ax.set_xticks([])\n","ax.set_yticks([])\n","\n","# Remove the surrounding box\n","ax.spines['top'].set_visible(False)\n","ax.spines['bottom'].set_visible(False)\n","ax.spines['left'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","\n","# Save the graph as a pickle file\n","output_path = '/content/expanded_pgx_biomarker_interact.pkl'\n","with open(output_path, 'wb') as f:\n","    pickle.dump(G_expanded_pgx, f)\n"],"metadata":{"id":"gaqqNfbbJPwS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Prompt generation"],"metadata":{"id":"nqIz3LCGJpIy"}},{"cell_type":"code","source":["import random\n","import networkx as nx\n","import pickle\n","\n","# Load the knowledge graph from the pickle file\n","with open('gene_disease_network.pkl', 'rb') as file:\n","    knowledge_graph = pickle.load(file)\n","\n","# Set the zero-hop entities (V0) based on the mentioned entities in the article\n","# Replace the following list with the entities mentioned in your article\n","zero_hop_entities = ['Cholesterol', 'LDL cholesterol']\n","\n","# Grow zero-hop entities to include one-hop entities (V1) and two-hop entities (V2)\n","one_hop_entities = set()\n","two_hop_entities = set()\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        one_hop_entities.update(knowledge_graph[entity])\n","        for one_hop_entity in knowledge_graph[entity]:\n","            if one_hop_entity in knowledge_graph:\n","                two_hop_entities.update(knowledge_graph[one_hop_entity])\n","\n","# Create the central graph (GC) using V0 and V1\n","central_graph = nx.Graph()\n","central_graph.add_nodes_from(zero_hop_entities)\n","central_graph.add_nodes_from(one_hop_entities)\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        central_graph.add_edges_from([(entity, one_hop_entity) for one_hop_entity in knowledge_graph[entity]])\n","\n","# Create the multi-hop graph (GM) using V1 and V2\n","multi_hop_graph = nx.Graph()\n","multi_hop_graph.add_nodes_from(one_hop_entities)\n","multi_hop_graph.add_nodes_from(two_hop_entities)\n","\n","for entity in one_hop_entities:\n","    if entity in knowledge_graph:\n","        multi_hop_graph.add_edges_from([(entity, two_hop_entity) for two_hop_entity in knowledge_graph[entity]])\n","\n","# Perform Random Walk\n","def perform_random_walk(graph, start_node, num_steps):\n","    random_walk = [start_node]\n","    current_node = start_node\n","    for _ in range(num_steps):\n","        neighbors = list(graph.neighbors(current_node))  # Assuming the graph is represented as an adjacency list\n","        if not neighbors:\n","            break\n","        next_node = random.choice(neighbors)\n","        random_walk.append(next_node)\n","        current_node = next_node\n","    return random_walk\n","\n","# Generate Keywords from Random Walks\n","num_steps = 5  # Number of steps for the random walk\n","num_prompts = 10  # Number of prompts to generate\n","\n","prompt_templates = [\n","    \"Discuss the relationship between {} and {} in the context of your topic of interest.\",\n","    \"Explain the impact of {} on {} in the context of your topic of interest.\",\n","    \"Describe the role of {} in relation to {} in the context of your topic of interest.\",\n","    \"Provide an overview of the interactions between {} and {} in the context of your topic of interest.\",\n","    \"Investigate the correlation between {} and {} in the context of your topic of interest.\",\n","    \"Elaborate on the significance of {} with respect to {} in the context of your topic of interest.\",\n","    \"Examine the implications of {} on {} in the context of your topic of interest.\",\n","    \"Analyze the associations between {} and {} in the context of your topic of interest.\",\n","    \"Evaluate the connections between {} and {} in the context of your topic of interest.\",\n","    \"Explore the interplay between {} and {} in the context of your topic of interest.\"\n","]\n","\n","generated_prompts1 = []  # List to store the generated prompts\n","\n","for _ in range(num_prompts):\n","    central_start_node = random.choice(list(central_graph))  # Start node for the central graph random walk\n","    multi_hop_start_node = random.choice(list(multi_hop_graph))  # Start node for the multi-hop graph random walk\n","\n","    central_random_walk = perform_random_walk(central_graph, central_start_node, num_steps)\n","    multi_hop_random_walk = perform_random_walk(multi_hop_graph, multi_hop_start_node, num_steps)\n","\n","    central_keyword = central_random_walk[-1]  # Last node of the central graph random walk\n","    multi_hop_keyword = multi_hop_random_walk[-1]  # Last node of the multi-hop graph random walk\n","\n","    # Select a random prompt template\n","    prompt_template = random.choice(prompt_templates)\n","\n","    # Generate Prompt\n","    prompt = prompt_template.format(central_keyword, multi_hop_keyword)\n","\n","    generated_prompts1.append(prompt)  # Save the generated prompt to the list\n","\n","# Print the generated prompts\n","for prompt in generated_prompts1:\n","    print(\"Generated Prompt:\")\n","    print(prompt)\n","    print(\"---------------------------\")\n"],"metadata":{"id":"vhUS8O_IJndR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import networkx as nx\n","import pickle\n","\n","# Load the knowledge graph from the pickle file\n","shared_gene_disease_network_path = '/content/shared_gene_disease_network.pkl'\n","with open(shared_gene_disease_network_path, 'rb') as file:\n","    knowledge_graph = pickle.load(file)\n","\n","# Set the zero-hop entities (V0) based on the mentioned entities in the article\n","zero_hop_entities = ['UGT1A1', 'G6PD']\n","\n","# Grow zero-hop entities to include one-hop entities (V1) and two-hop entities (V2)\n","one_hop_entities = set()\n","two_hop_entities = set()\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        one_hop_entities.update(knowledge_graph[entity])\n","        for one_hop_entity in knowledge_graph[entity]:\n","            if one_hop_entity in knowledge_graph:\n","                two_hop_entities.update(knowledge_graph[one_hop_entity])\n","\n","# Create the central graph (GC) using V0 and V1\n","central_graph = nx.Graph()\n","central_graph.add_nodes_from(zero_hop_entities)\n","central_graph.add_nodes_from(one_hop_entities)\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        central_graph.add_edges_from([(entity, one_hop_entity) for one_hop_entity in knowledge_graph[entity]])\n","\n","# Create the multi-hop graph (GM) using V1 and V2\n","multi_hop_graph = nx.Graph()\n","multi_hop_graph.add_nodes_from(one_hop_entities)\n","multi_hop_graph.add_nodes_from(two_hop_entities)\n","\n","for entity in one_hop_entities:\n","    if entity in knowledge_graph:\n","        multi_hop_graph.add_edges_from([(entity, two_hop_entity) for two_hop_entity in knowledge_graph[entity]])\n","\n","# Perform Random Walk\n","def perform_random_walk(graph, start_node, num_steps):\n","    random_walk = [start_node]\n","    current_node = start_node\n","    for _ in range(num_steps):\n","        neighbors = list(graph.neighbors(current_node))  # Assuming the graph is represented as an adjacency list\n","        if not neighbors:\n","            break\n","        next_node = random.choice(neighbors)\n","        random_walk.append(next_node)\n","        current_node = next_node\n","    return random_walk\n","\n","# Generate Keywords from Random Walks\n","num_steps = 5  # Number of steps for the random walk\n","num_prompts = 10  # Number of prompts to generate\n","\n","prompt_templates = [\n","    \"Discuss how the relationship between {} and {} shapes the dynamics within your topic of interest.\",\n","    \"Compare and contrast the impact of {} and {} on your topic of interest, highlighting their distinct influences.\",\n","    \"Provide an overview of the evolving roles of {} and {} and their interplay within your topic of interest.\",\n","    \"Explore the potential future interactions between {} and {} and their implications for your topic of interest.\",\n","    \"Investigate the contrasting viewpoints on the correlation between {} and {} and analyze their relevance to your topic of interest.\",\n","    \"Examine the significance of {} in relation to {} and its implications for your topic of interest.\",\n","    \"Analyze the associations between {} and {} and evaluate their effects on your topic of interest.\",\n","    \"Evaluate the connections between {} and {} and their respective contributions to your topic of interest.\",\n","    \"Explore the interplay between {} and {} in different contexts and its impact on your topic of interest.\",\n","    \"Discuss the controversies surrounding the relationship between {} and {} and present your assessment in the context of your topic of interest.\"\n","]\n","\n","generated_prompts2 = []  # List to store the generated prompts\n","\n","for _ in range(num_prompts):\n","    central_start_node = random.choice(list(central_graph))  # Start node for the central graph random walk\n","    multi_hop_start_node = random.choice(list(multi_hop_graph))  # Start node for the multi-hop graph random walk\n","\n","    central_random_walk = perform_random_walk(central_graph, central_start_node, num_steps)\n","    multi_hop_random_walk = perform_random_walk(multi_hop_graph, multi_hop_start_node, num_steps)\n","\n","    central_keyword = central_random_walk[-1]  # Last node of the central graph random walk\n","    multi_hop_keyword = multi_hop_random_walk[-1]  # Last node of the multi-hop graph random walk\n","\n","    # Select a random prompt template\n","    prompt_template = random.choice(prompt_templates)\n","\n","    # Generate Prompt\n","    prompt = prompt_template.format(central_keyword, multi_hop_keyword)\n","\n","    generated_prompts2.append(prompt)  # Save the generated prompt to the list\n","\n","# Print the generated prompts\n","for prompt in generated_prompts2:\n","    print(\"Generated Prompt:\")\n","    print(prompt)\n","    print(\"---------------------------\")\n"],"metadata":{"id":"6bKnmnppJuyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import networkx as nx\n","import pickle\n","\n","# Load the knowledge graph from the pickle file\n","ppi_network_string_path = '/content/ppi_network_string.pkl'\n","with open(ppi_network_string_path, 'rb') as file:\n","    knowledge_graph = pickle.load(file)\n","\n","# Set the zero-hop entities (V0) based on the mentioned entities in the article\n","zero_hop_entities = ['CYP3A4', 'CYP2C9']\n","\n","# Grow zero-hop entities to include one-hop entities (V1) and two-hop entities (V2)\n","one_hop_entities = set()\n","two_hop_entities = set()\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        one_hop_entities.update(knowledge_graph[entity])\n","        for one_hop_entity in knowledge_graph[entity]:\n","            if one_hop_entity in knowledge_graph:\n","                two_hop_entities.update(knowledge_graph[one_hop_entity])\n","\n","# Create the central graph (GC) using V0 and V1\n","central_graph = nx.Graph()\n","central_graph.add_nodes_from(zero_hop_entities)\n","central_graph.add_nodes_from(one_hop_entities)\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        central_graph.add_edges_from([(entity, one_hop_entity) for one_hop_entity in knowledge_graph[entity]])\n","\n","# Create the multi-hop graph (GM) using V1 and V2\n","multi_hop_graph = nx.Graph()\n","multi_hop_graph.add_nodes_from(one_hop_entities)\n","multi_hop_graph.add_nodes_from(two_hop_entities)\n","\n","for entity in one_hop_entities:\n","    if entity in knowledge_graph:\n","        multi_hop_graph.add_edges_from([(entity, two_hop_entity) for two_hop_entity in knowledge_graph[entity]])\n","\n","# Perform Random Walk\n","def perform_random_walk(graph, start_node, num_steps):\n","    random_walk = [start_node]\n","    current_node = start_node\n","    for _ in range(num_steps):\n","        neighbors = list(graph.neighbors(current_node))  # Assuming the graph is represented as an adjacency list\n","        if not neighbors:\n","            break\n","        next_node = random.choice(neighbors)\n","        random_walk.append(next_node)\n","        current_node = next_node\n","    return random_walk\n","\n","# Generate Keywords from Random Walks\n","num_steps = 5  # Number of steps for the random walk\n","num_prompts = 10  # Number of prompts to generate\n","\n","prompt_templates = [\n","    \"Discuss how the relationship between {} and {} shapes the dynamics within your topic of interest.\",\n","    \"Compare and contrast the impact of {} and {} on your topic of interest, highlighting their distinct influences.\",\n","    \"Provide an overview of the evolving roles of {} and {} and their interplay within your topic of interest.\",\n","    \"Explore the potential future interactions between {} and {} and their implications for your topic of interest.\",\n","    \"Investigate the contrasting viewpoints on the correlation between {} and {} and analyze their relevance to your topic of interest.\",\n","    \"Examine the significance of {} in relation to {} and its implications for your topic of interest.\",\n","    \"Analyze the associations between {} and {} and evaluate their effects on your topic of interest.\",\n","    \"Evaluate the connections between {} and {} and their respective contributions to your topic of interest.\",\n","    \"Explore the interplay between {} and {} in different contexts and its impact on your topic of interest.\",\n","    \"Discuss the controversies surrounding the relationship between {} and {} and present your assessment in the context of your topic of interest.\"\n","]\n","\n","generated_prompts3 = []  # List to store the generated prompts\n","\n","for _ in range(num_prompts):\n","    central_start_node = random.choice(list(central_graph))  # Start node for the central graph random walk\n","    multi_hop_start_node = random.choice(list(multi_hop_graph))  # Start node for the multi-hop graph random walk\n","\n","    central_random_walk = perform_random_walk(central_graph, central_start_node, num_steps)\n","    multi_hop_random_walk = perform_random_walk(multi_hop_graph, multi_hop_start_node, num_steps)\n","\n","    central_keyword = central_random_walk[-1]  # Last node of the central graph random walk\n","    multi_hop_keyword = multi_hop_random_walk[-1]  # Last node of the multi-hop graph random walk\n","\n","    # Select a random prompt template\n","    prompt_template = random.choice(prompt_templates)\n","\n","    # Generate Prompt\n","    prompt = prompt_template.format(central_keyword, multi_hop_keyword)\n","\n","    generated_prompts3.append(prompt)  # Save the generated prompt to the list\n","\n","# Print the generated prompts\n","for prompt in generated_prompts3:\n","    print(\"Generated Prompt:\")\n","    print(prompt)\n","    print(\"---------------------------\")\n"],"metadata":{"id":"9Fd-b440J0Lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import networkx as nx\n","import pickle\n","\n","# Load the knowledge graph from the pickle file\n","expanded_pgx_biomarker_network_path = '/content/expanded_pgx_biomarker_interact.pkl'\n","with open(expanded_pgx_biomarker_network_path, 'rb') as file:\n","    knowledge_graph = pickle.load(file)\n","\n","# Set the zero-hop entities (V0) based on the mentioned entities in the article\n","zero_hop_entities = ['CYP3A4', 'CYP2C9']\n","\n","# Grow zero-hop entities to include one-hop entities (V1) and two-hop entities (V2)\n","one_hop_entities = set()\n","two_hop_entities = set()\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        one_hop_entities.update(knowledge_graph[entity])\n","        for one_hop_entity in knowledge_graph[entity]:\n","            if one_hop_entity in knowledge_graph:\n","                two_hop_entities.update(knowledge_graph[one_hop_entity])\n","\n","# Create the central graph (GC) using V0 and V1\n","central_graph = nx.Graph()\n","central_graph.add_nodes_from(zero_hop_entities)\n","central_graph.add_nodes_from(one_hop_entities)\n","\n","for entity in zero_hop_entities:\n","    if entity in knowledge_graph:\n","        central_graph.add_edges_from([(entity, one_hop_entity) for one_hop_entity in knowledge_graph[entity]])\n","\n","# Create the multi-hop graph (GM) using V1 and V2\n","multi_hop_graph = nx.Graph()\n","multi_hop_graph.add_nodes_from(one_hop_entities)\n","multi_hop_graph.add_nodes_from(two_hop_entities)\n","\n","for entity in one_hop_entities:\n","    if entity in knowledge_graph:\n","        multi_hop_graph.add_edges_from([(entity, two_hop_entity) for two_hop_entity in knowledge_graph[entity]])\n","\n","# Perform Random Walk\n","def perform_random_walk(graph, start_node, num_steps):\n","    random_walk = [start_node]\n","    current_node = start_node\n","    for _ in range(num_steps):\n","        neighbors = list(graph.neighbors(current_node))  # Assuming the graph is represented as an adjacency list\n","        if not neighbors:\n","            break\n","        next_node = random.choice(neighbors)\n","        random_walk.append(next_node)\n","        current_node = next_node\n","    return random_walk\n","\n","# Generate Keywords from Random Walks\n","num_steps = 5  # Number of steps for the random walk\n","num_prompts = 10  # Number of prompts to generate\n","\n","prompt_templates = [\n","    \"Discuss how the relationship between {} and {} shapes the dynamics within your topic of interest.\",\n","    \"Compare and contrast the impact of {} and {} on your topic of interest, highlighting their distinct influences.\",\n","    \"Provide an overview of the evolving roles of {} and {} and their interplay within your topic of interest.\",\n","    \"Explore the potential future interactions between {} and {} and their implications for your topic of interest.\",\n","    \"Investigate the contrasting viewpoints on the correlation between {} and {} and analyze their relevance to your topic of interest.\",\n","    \"Examine the significance of {} in relation to {} and its implications for your topic of interest.\",\n","    \"Analyze the associations between {} and {} and evaluate their effects on your topic of interest.\",\n","    \"Evaluate the connections between {} and {} and their respective contributions to your topic of interest.\",\n","    \"Explore the interplay between {} and {} in different contexts and its impact on your topic of interest.\",\n","    \"Discuss the controversies surrounding the relationship between {} and {} and present your assessment in the context of your topic of interest.\"\n","]\n","\n","generated_prompts4 = []  # List to store the generated prompts\n","\n","for _ in range(num_prompts):\n","    central_start_node = random.choice(list(central_graph))  # Start node for the central graph random walk\n","    multi_hop_start_node = random.choice(list(multi_hop_graph))  # Start node for the multi-hop graph random walk\n","\n","    central_random_walk = perform_random_walk(central_graph, central_start_node, num_steps)\n","    multi_hop_random_walk = perform_random_walk(multi_hop_graph, multi_hop_start_node, num_steps)\n","\n","    central_keyword = central_random_walk[-1]  # Last node of the central graph random walk\n","    multi_hop_keyword = multi_hop_random_walk[-1]  # Last node of the multi-hop graph random walk\n","\n","    # Select a random prompt template\n","    prompt_template = random.choice(prompt_templates)\n","\n","    # Generate Prompt\n","    prompt = prompt_template.format(central_keyword, multi_hop_keyword)\n","\n","    generated_prompts4.append(prompt)  # Save the generated prompt to the list\n","\n","# Print the generated prompts\n","for prompt in generated_prompts4:\n","    print(\"Generated Prompt:\")\n","    print(prompt)\n","    print(\"---------------------------\")\n"],"metadata":{"id":"kRrYDDjtJ0_m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Generate query"],"metadata":{"id":"CM4qzwgjLDMh"}},{"cell_type":"code","source":["\n","!pip install transformers\n","!pip install nltk\n","\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","import nltk\n","from nltk.translate.bleu_score import corpus_bleu\n","import numpy as np\n","from collections import Counter\n","\n","def calculate_entropy(queries, tokenizer):\n","    all_tokens = [tokenizer.encode(prompt, add_special_tokens=False) for prompt in queries]\n","    all_tokens_flat = [token for sublist in all_tokens for token in sublist]\n","    token_counts = Counter(all_tokens_flat)\n","    total_tokens = len(all_tokens_flat)\n","    token_probabilities = [count / total_tokens for count in token_counts.values()]\n","    entropy = -np.sum(token_probabilities * np.log2(token_probabilities))\n","    return entropy\n","\n","def generate_queries(generated_prompts1, generated_prompts2, generated_prompts3, generated_prompts4):\n","    # Concatenate the generated prompts into a single list\n","    all_prompts = generated_prompts1 + generated_prompts2 + generated_prompts3 + generated_prompts4\n","\n","    # Initialize the tokenizer and model\n","    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n","\n","    # Generate queries based on the concatenated prompts\n","    queries = []\n","\n","    for prompt in all_prompts:\n","        # Tokenize the prompt\n","        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n","\n","        # Generate query using the model with beam search\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids,\n","                max_length=50,\n","                num_beams=5,  # Set the number of beams for beam search\n","                num_return_sequences=1,\n","                do_sample=False,  # Disable sampling\n","            )\n","\n","        # Decode the generated query\n","        query = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        queries.append(query)\n","\n","    # Perform post-processing on the generated queries\n","    filtered_queries = list(set(queries))  # Remove duplicates\n","\n","    # Calculate Self-BLEU\n","    references = [filtered_queries] * len(filtered_queries)  # Treat each generated query as a reference\n","    self_bleu = corpus_bleu(references, filtered_queries)\n","\n","    # Calculate Distinct Uni-grams and Distinct Bi-grams\n","    all_unigrams = [token for prompt in filtered_queries for token in prompt.split()]\n","    all_bigrams = [\" \".join(bigram) for prompt in filtered_queries for bigram in nltk.bigrams(prompt.split())]\n","    distinct_unigrams = len(set(all_unigrams)) / len(all_unigrams)\n","    distinct_bigrams = len(set(all_bigrams)) / len(all_bigrams)\n","\n","    # Calculate entropy\n","    entropy = calculate_entropy(filtered_queries, tokenizer)\n","\n","    # Print the Self-BLEU score, Distinct Uni-grams, Distinct Bi-grams, and entropy\n","    print(\"Self-BLEU:\", self_bleu)\n","    print(\"Distinct Uni-grams:\", distinct_unigrams)\n","    print(\"Distinct Bi-grams:\", distinct_bigrams)\n","    print(\"Entropy:\", entropy)\n","\n","if __name__ == \"__main__\":\n","    # Replace the following lists with your generated prompts\n","    generated_prompts1 =  generated_prompts1\n","    generated_prompts2 =  generated_prompts2\n","    generated_prompts3 =  generated_prompts3\n","    generated_prompts4 =  generated_prompts4\n","\n","    generate_queries(generated_prompts1, generated_prompts2, generated_prompts3, generated_prompts4)\n"],"metadata":{"id":"kIPu5LI8LB8d"},"execution_count":null,"outputs":[]}]}